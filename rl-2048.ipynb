{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jvthunder/rl-2048?scriptVersionId=140301439\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install termtables\n!pip install pickle5\n!pip install gym\n!pip install six\n!pip install stable_baselines3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport termtables as tt\nimport random\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom collections import deque\nimport time\n\nimport gym\nfrom gym import spaces\nfrom gym.utils import seeding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Base2048Env(gym.Env):\n        \n    def __init__(self, SIZE=4, board=0 ,seed=None):\n        if seed is not None:\n            np.random.seed(seed)\n        \n        self.SIZE = SIZE\n        self.width = SIZE\n        self.height = SIZE\n        self.layers = self.width * self.height\n        \n        self.ACTION_STRING = ['left', 'up', 'right', 'down']\n        \n        self.observation_space = spaces.Box(0, 1, (self.layers, self.width, self.height), dtype=int)\n        self.action_space = spaces.Discrete(4)\n        \n        self.board = np.zeros((self.height, self.width)).astype(int)\n        self.Matrix = np.zeros((self.layers, self.width, self.height), int)\n        if type(board)==int:\n            self.reset()\n        else:\n            self.board = board\n            \n        self.score = 0\n        self.move_cnt = 0\n        self.prv_move = '-'\n        self.is_game_over = False\n    \n    def render(self):\n        \n        text = f\"2048 Board State Turn {self.move_cnt}\\n\"\n        text += f\"Score: {self.score}\\n\"\n        text += f\"Previous move: {self.prv_move}\\n\"\n\n        grid = tt.to_string(\n            self.board,\n            style=tt.styles.ascii_thin\n        )\n        text += grid\n        \n        if self.is_game_over:\n            text += f\"\\nYou lose. Your score is {self.score}\"\n\n        print(text)\n        \n    def stack(self):\n        self.Matrix = np.zeros((self.layers, self.width, self.height), int)\n        for i in range(self.height):\n            for j in range(self.width):\n                if self.board[i][j]!=0:\n                    dim = int(np.log2(self.board[i][j])-1)\n                    self.Matrix[dim, i, j] = 1\n        return self.Matrix\n\n    def reset(self):\n        self.board = np.zeros((self.height, self.width)).astype(int)\n        self.add_random()\n        self.add_random()\n        self.score = 0\n        self.move_cnt = 0\n        self.prv_move = '-'\n        self.is_game_over = False\n        return self.stack()\n    \n    def add_random(self):\n        number = 0\n        if np.random.randint(0,10) == 0:\n            number = 4\n        else:\n            number = 2\n\n        available = []\n        for i in range(self.height):\n            for j in range(self.width):\n                if self.board[i][j] == 0:\n                    available.append((i,j))\n        \n        idx = np.random.randint(0, len(available))\n        x, y = available[idx]\n        self.board[x][y] = number\n    \n    def merge_left(self, board):\n        valid = False\n        inc_score = 0\n        new_board = np.zeros((self.height, self.width)).astype(int)\n\n        for i in range(self.height):\n            latest_num = board[i][0]\n            latest_pos = 0\n            new_board[i][latest_pos] = latest_num\n\n            for j in range(1,self.width):\n                if board[i][j] == 0:\n                    continue\n                if latest_num == 0:\n                    latest_num = board[i][j]\n                    new_board[i][latest_pos] = latest_num\n                    valid = True\n                elif latest_num == board[i][j]:\n                    latest_num += board[i][j]\n                    new_board[i][latest_pos] = latest_num\n                    inc_score += latest_num\n                    valid = True\n                else:\n                    latest_num = board[i][j]\n                    latest_pos += 1\n                    new_board[i][latest_pos] = latest_num\n                    if latest_pos != j:\n                        valid = True \n        return new_board, valid, inc_score\n    \n    def check_game_over(self):\n        for i in range(len(self.board)):\n            if 2048 in self.board[i]:\n                return True\n        \n        for idx in [0,1,2,3]:\n            copy_board = np.rot90(self.board, k = idx)\n            copy_board, valid, _ = self.merge_left(copy_board)\n            if valid == True:\n                return False\n        return True\n\n    def step(self, action):\n        if self.is_game_over:\n            self.reset()\n            self.is_game_over = False\n        \n        if action not in self.action_space:\n            self.prv_move = '-'\n            return self.Matrix, 0, self.is_game_over, {}\n        \n        copy_board = np.rot90(self.board, k = action)\n        copy_board, valid, inc_score = self.merge_left(copy_board)\n        self.score += inc_score \n        \n        self.prv_move = self.ACTION_STRING[action]\n        if valid == False:\n            return self.Matrix, 0, self.is_game_over, {}\n        \n        self.board = np.rot90(copy_board, k = -action)\n        self.move_cnt += 1\n        self.add_random()\n        self.is_game_over = self.check_game_over()\n        \n        return self.stack(), inc_score, self.is_game_over, {}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = Base2048Env()\nobs = env.reset()\n# env.render()\n# print(obs.shape)\n# print(env.observation_space)\n\nfor i in range(10):\n    action = env.action_space.sample()\n    observation, reward, done, info = env.step(action)\n#     print(observation.shape)\n    env.render()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from stable_baselines3 import PPO\n\ndef make_env():\n    env = Base2048Env()\n    return env\n\nenv = make_env()\nenv.reset()\nmodel = PPO('MlpPolicy', env, verbose=1,\n            n_steps=1024,\n            batch_size=32, \n            gamma=0.9,\n            learning_rate=0.0001,\n            ent_coef=0.01,\n            n_epochs=32,\n            )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TIMESTEPS = 1024 * 1000\nmodel.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"PPO\")\nmodel.save(f\"models/PPO/{TIMESTEPS}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nenv = Base2048Env()\nobservation = env.reset()\nenv.render()\ndone = False\nfor i in range(1000):\n    observation = torch.FloatTensor(observation).unsqueeze(0)\n    action, _ = model.predict(observation)\n    action = action[0]\n    observation, reward, done, info = env.step(action)\n    env.render()\n    if done: break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}